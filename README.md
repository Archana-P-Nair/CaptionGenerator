# ğŸ–¼ï¸ Image Caption Generator using Deep Learning

ğŸš€ A full-stack **Image Caption Generator** that automatically generates meaningful captions for images using **CNN + LSTM** architecture, wrapped with a **frontend UI**, **backend API**, and **deployed for real-world usage**.

This project combines **Computer Vision**, **Natural Language Processing**, and **Web Development**, making it a strong end-to-end ML application.

---

## ğŸŒŸ Live Demo
ğŸ”— **Deployed Application:** *(Add your deployed URL here)*  
ğŸ“¦ **GitHub Repository:** https://github.com/Archana-P-Nair/CaptionGenerator

---

## ğŸ“Œ Project Overview

The goal of this project is to generate **human-like captions** for images by learning visual features and linguistic patterns.

ğŸ” The system:
- Takes an image as input
- Extracts visual features using a pre-trained CNN
- Generates captions **word-by-word** using an LSTM
- Serves predictions through a **backend API**
- Displays results via a **frontend interface**

---

## ğŸ§  Model Architecture

ğŸ§© The model is built using a **CNN + RNN (LSTM)** hybrid approach:

### ğŸ”¹ CNN â€“ Image Feature Extraction
- **Model:** Xception (pre-trained on ImageNet)
- **Output:** 2048-dimensional feature vector
- **Why Xception?**
  - Strong feature extraction
  - Faster convergence using transfer learning

### ğŸ”¹ RNN â€“ Caption Generation
- **Embedding Layer:** Converts word indices into dense vectors
- **LSTM:** Captures sequence context
- **Softmax Layer:** Predicts the next word in the caption

ğŸ“Œ Image features and text embeddings are merged to predict captions sequentially.

---

## ğŸ“‚ Dataset

ğŸ“¦ **Flickr8K Dataset**
- ~8,000 images
- 5 captions per image
- ~8,763 unique words

ğŸ”§ Preprocessing includes:
- Lowercasing text
- Removing punctuation & numbers
- Adding `<start>` and `<end>` tokens
- Tokenization & padding

---

## ğŸ”„ Workflow

1ï¸âƒ£ Load and preprocess captions  
2ï¸âƒ£ Extract image features using Xception  
3ï¸âƒ£ Tokenize and pad caption sequences  
4ï¸âƒ£ Train CNN + LSTM model using a data generator  
5ï¸âƒ£ Save model checkpoints  
6ï¸âƒ£ Generate captions iteratively during inference  
7ï¸âƒ£ Serve predictions via backend  
8ï¸âƒ£ Display results on frontend UI  

---

## ğŸ› ï¸ Tech Stack

### ğŸ§  Machine Learning
- TensorFlow / Keras
- CNN (Xception)
- RNN / LSTM
- NumPy, Pandas
- Pickle (feature storage)

### ğŸŒ Backend
- Python
- Flask / FastAPI *(whichever you used)*
- REST API for inference

### ğŸ¨ Frontend
- HTML / CSS / JavaScript *(or React, if used)*
- Image upload interface
- Caption display

### â˜ï¸ Deployment
- Model served via backend API
- Frontend + backend deployed *(platform: Render / Vercel / AWS / Heroku etc.)*

---

## ğŸ“Š Model Configuration

| Component                  | Value |
|---------------------------|------|
| Dataset                   | Flickr8K |
| CNN Model                 | Xception |
| Image Size                | 299 Ã— 299 |
| Feature Vector Size       | 2048 |
| Embedding Dimension       | 256 |
| LSTM Units                | 256 |
| Loss Function             | Categorical Crossentropy |
| Optimizer                 | Adam |
| Batch Size                | 32 |
| Caption Generation        | Word-by-word |

---

## ğŸ§ª Caption Generation Logic

ğŸ§  Caption generation follows this loop:

- Start with `<start>` token
- Predict next word using model
- Append predicted word
- Repeat until `<end>` token or max length

ğŸ“Œ This ensures grammatically coherent captions.

---

## ğŸ–¥ï¸ Application Features

âœ¨ Upload any image  
âœ¨ Generate captions instantly  
âœ¨ Clean & interactive UI  
âœ¨ Backend-powered inference  
âœ¨ Deployed and accessible online  

---

## ğŸ“ Project Structure

